---
layout: post
title: Hadoop1.x hdfs-site.xml 参数设定
category: hadoop
---

h2. 平台环境

* CentOS 6.X
* JDK 1.7
* Hadoop 1.0.4 

h2. 参照 "hdfs-default.xml":http://hadoop.apache.org/docs/r1.0.4/hdfs-default.html

h3. NameNode

h2. dfs.name.dir

*预设值* : ${hadoop.tmp.dir}/dfs/name
*说明* : 指定本机上存取 fsimage 及 editlog 的目录，这个目录非常的重要，如果损毁就无法存取 HDFS 的资料了，所以不建议放在 ${hadoop.tmp.dir} 目录下。更好的做法是用 “,” 指定多个目录，Hadoop 会复制 fsimage 的资料到所有的目录下，如果其中一个目录损毁 Hadoop 会自动使用正常的目录并把对的资料再复制到损毁的目录下。
指定多个目录后在 HDFS portal 会看到多个目录，正常状况会是 Active，当损毁时会变成 Inactive

h2. dfs.namenode.logging.level

*预设值* : info
*说明* : 这个值是指定 namenode 的 logging level。其他的值有:

* dir : 看 namenode server 的变化
* block : 看 blocks 新增刪除或 replication 的变化
* all : 显示全部的 log

除非是为了 debug，不然不建议用其他的等級，会造成 Hadoop 的 log 档案太大。

h2. dfs.http.address

*预设值* : 0.0.0.0:50070
*说明* : Web UI 用的 port。除非是为了 security 的考量才会需要改 binding 的 IP/Port，不然不需要改这个值。

h2. dfs.https.enable

*预设值* : false
*说明* : namenode 预设并没有启动 https，在设定 https 的 IP/Port 之前要先确定这个值设为 true。

h2. dfs.https.address

*预设值* : 0.0.0.0:50470
*说明* : Web UI 用的 port，用 https protocol。除非是为了 security 的考量才会需要改 binding 的 IP/Port，不然不需要改这个值。

h2. dfs.replication

*预设值* : 3
*说明* : 预设 blocks 的备份数量。如果不需要太多的备份或 cluster 比较小，可以改为 2。Client 端也可以根据使用状况自行更改这个值。只是如果所设的值小于 dfs.replication，在执行 hadoop fsck 指令时会看到这个 block 被标示为 Under-Replicated Blocks。至于备份的机制可以参考 "Hadoop1.x core-site.xml 参数设定":http://chxt6896.github.com/hadoop/2013/01/25/hadoop-core-site.html 里的 topology.script.file.name 说明。

h2. dfs.replication.min

*预设值* : 1
*说明* : 不需要特别改这个值。因为并不是所有在 HDFS 上的资料都需要有 3 份备份，这可以由 client 来決定。如果对资料备份非常敏感可以把这个值设为跟 dfs.replication 一样。

h2. dfs.replication.max

*预设值* : 512
*说明* : 因为 client 可以自行决定每个 block 要有几份备份，为了怕误操作导致备份过多而影响整個 cluster 的使用量，建议给一个小一点的值，例如 10。

h2. dfs.block.size

*预设值* : 67108864(byte)
*说明* : 预设每个 block 是 64MB。如果确定存取的档案都很大可以改为 134217728(128MB)。Client 也可自行决定要使用的 block size 而不需要更改整个 cluster 的设定。

{% highlight bash linenos %}
$ hadoop fs -D dfs.block.size=134217728 -put local_name remote_location
{% endhighlight %}

h2. dfs.safemode.threshold.pct

*预设值* : 0.999f
*说明* : Hadoop 在启动时预设会进入 safe mode，也就是只读模式，这时是不能写入资料的。只有当 99.9% 的 blocks 达到最小的 dfs.replication.min 数量(预设是 1)才会离开 safe mode。在 dfs.replication.min 设的比较大或 data nodes 数量较多时会等比较久。

下面讨论两个极端的状况:

* 设为大于 1 : 表示永远不会离开 safe mode，这在当 Hadoop cluster 需要做 migration 时很好用，既可继续提供读取服务，又可防止使用者写入资料导致 migration 不完全。
* 设为 0 : 表示不会启动 safe mode。在 local 测试时会非常的方便，不然常常需要等一段时间或直接执行下面才能离开 safe mode。

{% highlight bash linenos %}
$ hadoop dfsadmin -safemode leave
{% endhighlight %}

h2. dfs.hosts

*预设值* : N/A
*说明* : 预设不指定的状况下，只要 datanodes 在 hdfs-site.xml 指定 namenode，在 mapred-site.xml 指定 jobtracker 的位址就可以加入这个 cluster。但是为了安全的考虑，系统管理者可能要决定只有特定的 nodes 可以加入。此值是指定一个档案位置，名字可自取，例如 : /etc/hadoop/conf/dfs-hosts，并列出所有可以连接 namenode 的机器清单。不在清单上的机器是没有权限的。在 mapred-site.xml 里也有个类似的值 mapred.hosts 来指定可以连 jobtracker 的机器清单。

h2. dfs.hosts.exclude

*预设值* : N/A
*说明* : 当需要淘汰或移除多台机器时会用到。理论上一台机器无预期的宕机，Hadoop 会侦测并把该机器上的 blocks 搬到其他的 datanodes 上，并不需要系统管理员做额外的动作。但是停掉多台机器的情况下是有风险的，假设备份个数为 3 并停掉三台机器，则有一定的机率某些 blocks 正好只在这三台机器上，移掉之后资料也救不回来了。正确的做法是先告诉 namenode 这些机器将被移除，让 namenode 把上面的资料全部备份到其他的 datanodes 上，再进行停机。跟 dfs.hosts 一样，指定一个档案位置，名字可自取，例如 : /etc/hadoop/conf/dfs-exclude-hosts，并列出所有需淘汰的机器清单。设定后要执行以下的指令通知 namenode 做搬资料的动作。

{% highlight bash linenos %}
$ hadoop dfsadmin -refreshNodes
{% endhighlight %}

进度可以在 Web UI 上看到，当该 datanodes 的状态显示为 Decommissioned 表示可以安全的移除机器了。


h2. dfs.support.append

*预设值* : false
*说明* : 指定是否可在 HDFS 原有档案內容之后加入新资料。看 hfds-default.xml 里对这个参数的说明是有 bug “This is currently set to false because there are bugs in the ‘append code’ and is not supported in any prodction cluster.”。但是 HBase Configuration 里另外说明了以上的咨询是过时的，在 Cloudera 及 MapR 的版本都已经加入了这个功能。如果有使用 HBase，为了避免资料遗失，请把这个值设为 true。

h2. dfs.namenode.handler.count

*预设值* : 10
*说明* : 设定 namenode server threads 的数量，这些 threads 会用 RPC 跟其他的 datanodes 沟通。当 datanodes 数量太多时会发现很容易出現 RPC timeout，解决方法是提升网络速度或调高这个值，但要注意的是 thread 数量多也表示 namenode 吃的内存也随着增加。在 "Hadoop Cluster Setup":http://hadoop.apache.org/docs/r0.20.2/cluster_setup.html 这篇文章里提到 900 个 nodes 只需要设成 40，但是个人经验是 100 个 nodes 配 100 个 threads。

h2. dfs.namenode.keytab.file

*预设值* : N/A
*说明* : 当 core-site.xml 里的 hadoop.security.authentication 参数设为 “kerberos” 时就要指定 keytab 的位置。例如 : /etc/hadoop/conf/hdfs.keytab

h2. dfs.namenode.kerberos.principal

*预设值* : N/A
*说明* : 指定 kerberos principal 名称，这在产生 keytab 档案时会指定，一般常用的命名规则是 hdfs/_HOST@KERBEROS-REALM.COM
 
h3. Secondary NameNode 
 
h2. dfs.secondary.namenode.keytab.file

*预设值* : N/A
*说明* : 当 core-site.xml 里的 hadoop.security.authentication 参数设为 “kerberos” 时就要指定 keytab 的位置。例如 : /etc/hadoop/conf/hdfs.keytab

h2. dfs.secondary.namenode.kerberos.principal

*预设值* : N/A
*说明* : 指定 kerberos principal 名称，这在产生 keytab 档案时会指定，一般常用的命名规则是 hdfs/_HOST@KERBEROS-REALM.COM

h3. DataNode

h2. dfs.data.dir

*预设值* : ${hadoop.tmp.dir}/dfs/data
*说明* : 指定本机上放 data nodes 资料的目录，如果要指定多个目录(volumes)可用 “,” 分隔。在 production 环境会指定多个，并设定 dfs.datanode.failed.volumes.tolerated。一般来说，多个目录会对应到系统上不同的 partitions，不同的硬盘。设定多个可加快存取速度，及避免硬盘坏掉需要抽换用。

h2. dfs.datanode.address

*预设值* : 0.0.0.0:50010
*说明* : datanode service 监听的 port，用来传输资料用。除非是为了 security 的考虑才会需要改 binding 的 IP/Port，不然不需要改这个值。

h2. dfs.datanode.http.address

*预设值* : 0.0.0.0:50075
*说明* : Web UI 用的 port。除非是为了 security 的考虑才会需要改 binding 的 IP/Port，不然不需要改这个值。

h2. dfs.datanode.handler.count

*预设值* : 3
*说明* : 指定 data node 上用的 thread 数量。在 production 的环境建议调到 100。

h2. dfs.datanode.max.xcievers

*预设值* : 256
*说明* : 这个值是指定 datanode 可同时处理的最大档案数量。但是预设值很小，当多个或一个大型程序存取时会发生下面的错误讯息

<pre>
10/12/08 20:10:31 INFO hdfs.DFSClient: Could not obtain block blk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node: java.io.IOException: 
No live nodes contain current block. Will get new block locations from namenode and retry... 
</pre>

以使用 HBase 为例，建议值是 4096。如果还有多个程序存取可再乘 2。

h2. dfs.datanode.failed.volumes.tolerated

*预设值* : 0
*说明* : 这个值要对应 dfs.data.dir 参数设定的目录个数，0 表示只要有任何一个 volume 坏掉 data nodes 就会被强制停掉。假设挂载 n 个 volumns，Hadoop 会确定 n – dfs.datanode.failed.volumes.tolerated 不能小于 0。设定错误在启动 data node 会看到下面的信息

<pre>
2011-08-27 11:53:03,785 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: org.apache.hadoop.util.DiskChecker$DiskErrorException: Invalid value for validVolsRequired : -1 ,  Current valid volumes: 1
        at org.apache.hadoop.hdfs.server.datanode.FSDataset.<init>(FSDataset.java:906)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:373)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:282)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1544)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1484)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1502)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:1627)
        at org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.start(SecureDataNodeStarter.java:103)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.commons.daemon.support.DaemonLoader.start(DaemonLoader.java:177)
</pre>

如果 data volumns 有 4 个，dfs.datanode.failed.volumes.tolerated 可设为 2。表示当有 2 个硬盘坏掉时 data nodes 还是可以正常运作。这时只要换坏硬盘即可，并不需要停掉 data nodes。

h2. dfs.datanode.data.dir.perm

*预设值* : 700
*说明* : 这个值是设定 data node 写资料到 local disk 上的权限。使用 POSIX 表示法。在 production 上为了 security 考虑，不建议改这个参数。如果是测试环境为了方便其他 users 用工具分析资料，可以改成 755。

h2. dfs.datanode.du.reserved

*预设值* : 0(byte)
*说明* : 预设值表示 data nodes 会使用整个 volumns，写满之后会导致无法再写入 M/R jobs 或启动 data nodes 时的暂存档。如果还有其他程序共用这些目录也会受到影响。建议保留至少 1073741824(1G) 的空间。

h2. dfs.datanode.keytab.file

*预设值* : N/A
*说明* : 指定 kerberos principal 名称，这在产生 keytab 档案时指定，一般常用的命名规则是 hdfs/_HOST@KERBEROS-REALM.COM

h2. dfs.namenode.kerberos.principal

*预设值* : N/A
*说明* : 当 core-site.xml 里的 hadoop.security.authentication 参数设为 “kerberos” 时就要指定 keytab 的位置。例如 : /etc/hadoop/conf/hdfs.keytab

h2. dfs.datanode.kerberos.principal

*预设值* : N/A
*说明* : 指定 kerberos principal 名称，这在产生 keytab 档案时指定，一般常用的命名规则是 hdfs/_HOST@KERBEROS-REALM.COM

h3. Etc

h2. dfs.balance.bandwidthPerSec

*预设值* : 1048576(byte)
*说明* : 这个值是决定 file blocks 从一个 data node 搬到另一个 data node 的速度, 预设为 1MB。主要是用在 re-balance，如果觉得执行速度太慢可以调整这个参数加快 blocks 的搬移。但是这也表示会多占带宽，可能会影响正常 M/R jobs 或 applications 的执行。建议值为 4194304(4MB)

<a href="http://fenriswolf.me/2012/05/25/hadoop-%E5%8F%83%E6%95%B8%E8%A8%AD%E5%AE%9A-hdfs-site-xml/"> >>Hadoop 參數設定 – hdfs-site.xml</a>
