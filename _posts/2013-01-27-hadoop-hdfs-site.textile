---
layout: post
title: Hadoop1.x hdfs-site.xml 参数设定
category: hadoop
---

h2. 平台环境

* CentOS 6.X
* JDK 1.7
* Hadoop 1.0.4 

h2. 参照 "hdfs-default.xml":http://hadoop.apache.org/docs/r1.0.4/hdfs-default.html

h3. NameNode

h2. dfs.name.dir

*预设值* : ${hadoop.tmp.dir}/dfs/name
*说明* : 指定本机上存取 fsimage 及 editlog 的目录，这个目录非常的重要，如果损毁就无法存取 HDFS 的资料了，所以不建议放在 ${hadoop.tmp.dir} 目录下。更好的做法是用 “,” 指定多个目录，Hadoop 会复制 fsimage 的资料到所有的目录下，如果其中一个目录损毁 Hadoop 会自动使用正常的目录并把对的资料再复制到损毁的目录下。
指定多个目录后在 HDFS portal 会看到多个目录，正常状况会是 Active，当损毁时会变成 Inactive

h2. dfs.namenode.logging.level

*预设值* : info
*说明* : 这个值是指定 namenode 的 logging level。其他的值有:

* dir : 看 namenode server 的变化
* block : 看 blocks 新增刪除或 replication 的变化
* all : 显示全部的 log

除非是为了 debug，不然不建议用其他的等級，会造成 Hadoop 的 log 档案太大。

h2. dfs.http.address

*预设值* : 0.0.0.0:50070
*说明* : Web UI 用的 port。除非是为了 security 的考量才会需要改 binding 的 IP/Port，不然不需要改这个值。

h2. dfs.https.enable

*预设值* : false
*说明* : namenode 预设并没有启动 https，在设定 https 的 IP/Port 之前要先确定这个值设为 true。

h2. dfs.https.address

*预设值* : 0.0.0.0:50470
*说明* : Web UI 用的 port，用 https protocol。除非是为了 security 的考量才会需要改 binding 的 IP/Port，不然不需要改这个值。

h2. dfs.replication

*预设值* : 3
*说明* : 预设 blocks 的备份数量。如果不需要太多的备份或 cluster 比较小，可以改为 2。Client 端也可以根据使用状况自行更改这个值。只是如果所设的值小于 dfs.replication，在执行 hadoop fsck 指令时会看到这个 block 被标示为 Under-Replicated Blocks。至于备份的机制可以参考 "Hadoop1.x core-site.xml 参数设定":http://chxt6896.github.com/hadoop/2013/01/25/hadoop-core-site.html 里的 topology.script.file.name 说明。

h2. dfs.replication.min

*预设值* : 1
*说明* : 不需要特别改这个值。因为并不是所有在 HDFS 上的资料都需要有 3 份备份，这可以由 client 来決定。如果对资料备份非常敏感可以把这个值设为跟 dfs.replication 一样。

h2. dfs.replication.max

*预设值* : 512
*说明* : 因为 client 可以自行决定每个 block 要有几份备份，为了怕误操作导致备份过多而影响整個 cluster 的使用量，建议给一个小一点的值，例如 10。

h2. dfs.block.size

*预设值* : 67108864(byte)
*说明* : 预设每个 block 是 64MB。如果确定存取的档案都很大可以改为 134217728(128MB)。Client 也可自行决定要使用的 block size 而不需要更改整个 cluster 的设定。

{% highlight bash linenos %}
$ hadoop fs -D dfs.block.size=134217728 -put local_name remote_location
{% endhighlight %}

h2. dfs.safemode.threshold.pct

*预设值* : 0.999f
*说明* : Hadoop 在启动时预设会进入 safe mode，也就是只读模式，这时是不能写入资料的。只有当 99.9% 的 blocks 达到最小的 dfs.replication.min 数量(预设是 1)才会离开 safe mode。在 dfs.replication.min 设的比较大或 data nodes 数量较多时会等比较久。

下面讨论两个极端的状况:

* 设为大于 1 : 表示永远不会离开 safe mode，这在当 Hadoop cluster 需要做 migration 时很好用，既可继续提供读取服务，又可防止使用者写入资料导致 migration 不完全。
* 设为 0 : 表示不会启动 safe mode。在 local 测试时会非常的方便，不然常常需要等一段时间或直接执行下面才能离开 safe mode。

{% highlight bash linenos %}
$ hadoop dfsadmin -safemode leave
{% endhighlight %}

h2. hadoop.security.authentication

*预设值* : simple
*说明* : simple 表示沒有 authentication，Hadoop 会用 system account 及 group 来控管权限。另外可以指定为 kerberos，这部分相对比较复杂，要有一个 kerberos server 并产生 account keytab，在执行任何操作前 client 要先用 kinit 指令对 kerberos server 认证，之后的任何操作都是以 kerberos account 来执行。

h2. hadoop.kerberos.kinit.command

*预设值* : N/A
*说明* : 如果 hadoop.security.authentication 设为 kerberos 就要多设这个参数指定 Kerberos kinit 指令的路径。在 CentOS 装 krb5-workstation package 后预设安装路径为 /usr/kerberos/bin/kinit。

h2. fs.trash.interval

*预设值* : 0(分)
*说明* : 清掉垃圾筒的时间。预设是不清, 所以在刪除资料时要自己执行

hadoop fs -rm -skipTrash 或 hadoop fs -expunge 

来清除垃圾筒的资料，但是强制用 -skipTrash 会造成误刪的资料救不回来，user 也常常会忘记做 -expunge 而造成 Hadoop 空间不会释放。建议可以设为 1440 让 Hadoop 每天清除垃圾筒。

h2. topology.script.file.name

*预设值* : N/A
*说明* : 用作 Hadoop Rack Awareness 的机制，指定一个可执行档，input 会是一组 hostname 或 ip，回传值是 rack name 清单。不指定的情況下，Hadoop 会预设所有的 node 都在同一个 rack 之下。
以下是一个 python 的范例，不过用 shell script 或其他语言写也可以

{% highlight bash python %}
#!/usr/bin/python

import sys
from string import join

DEFAULT = '/dc/rack0';

RACK_MAP = {
    '10.1.113.37' : '/dc/rack1',
    'hadoop-worker01' : '/dc/rack1',
    
    '10.1.113.77' : '/dc/rack1',
    'hadoop-worker02' : '/dc/rack1',
    
    '10.1.113.45' : '/dc/rack2',
    'hadoop-work03' : '/dc/rack2',
    
    '10.1.113.48' : '/dc/rack2',
    'hadoop-work04' : '/dc/rack2',
  }

if len(sys.argv) == 1:
    print DEFAULT
else:
    print join([RACK_MAP.get(i, DEFAULT) for i in sys.argv[1:]]," ")
{% endhighlight %}

一个非常大的 Hadoop cluster 可能会跨多个 data centers，每个 data center 会有多个 racks，每个 rack 有多个 nodes。假设 Hadoop replication number 设 3，在 Hadoop 做 replication 时会根据这个设定，第一份资料放在 local node，第二份资料放在另一个 rack 的某个 node，第三份资料会放在与第二份同个 rack 但不同的 node 下。当网络设定有问题或断线时，某一个 rack 可能会全部不见，放在不同的 rack 可以保证仍然能存取到资料。为了增加网络的容错能力，一般都会设定这个 script。
如果在 cluster 已经有资料的情况下才设定 rack topology，可以用 hadoop balancer 指令让所有的 blocks 重新分配

h2. topology.script.number.args

*预设值* : 100
*说明* : 每次传給 topology.script.file.name script 的参数个数。如果 Hadoop node 个数过多，topology.script.file.name script 会被执行多次，一次传入 100 个参数
 

h2. hadoop.native.lib

*预设值* : true
*说明* : 预设 Hadoop 会去找所有可用的 native libraries 并自动 load 进来使用，例如压缩类的 libraries 像 GZIP, LZO 等等。会设成 false 的原因通常是为了 debug，Hadoop 会把 native libraries 换成相对应的 java 实作方式来执行，例如 GZIP，以方便使用者检测 libraries 是否执行错误。但是 LZO 这类的 libraries 并没有 java 实作，所以还是会 call native libraries 来做压缩，也就沒有 debug 的效果了。详细的压缩格式类型会在 mapred-site.xml 的设定时再介绍。
